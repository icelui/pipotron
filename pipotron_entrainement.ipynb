{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"pipotron_entrainement.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rMzMUl-nGL_t","executionInfo":{"status":"ok","timestamp":1615971569892,"user_tz":-60,"elapsed":733,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"72ec380d-9923-4573-baad-1586f76b2b1a"},"source":["import numpy as np\n","import pandas as pd\n","from google.colab import drive\n","drive.mount('/drive')\n","%cd /drive/MyDrive/data/pipotron/\n","%pwd\n","%ls -al"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n","/drive/MyDrive/data/pipotron\n","total 100\n","drwx------ 2 root root  4096 Mar 16 10:48 \u001b[0m\u001b[01;34mdonnees\u001b[0m/\n","drwx------ 8 root root  4096 Mar 16 10:40 \u001b[01;34m.git\u001b[0m/\n","-rw------- 1 root root  1819 Mar 16 11:10 .gitignore\n","-rw------- 1 root root  4451 Mar 16 12:39 git.ipynb\n","drwx------ 3 root root  4096 Mar 16 10:46 \u001b[01;34mmodels\u001b[0m/\n","-rw------- 1 root root 82075 Mar 17 08:59 pipotron_entrainement.ipynb\n","-rw------- 1 root root    79 Mar 16 10:40 README.md\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"zmI30JueGL_4","executionInfo":{"status":"ok","timestamp":1615969768511,"user_tz":-60,"elapsed":2649,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"3c846f1c-8b1e-4a71-a12f-0c68e59e542d"},"source":["# Chargement des données :\n","\n","from_full_table = False\n","reviews_filename = \"donnees/review_only.txt\"\n","\n","if from_full_table:\n","  # Chargement du fichier complet, issu du scraping du site larvf.com (données accessibles par abonnement, non publiques):\n","  DF_rvf = pd.read_csv(\"/drive/MyDrive/donnees/larvf_2020-11-24.csv\")\n","  print(\"Nombre de revues textuelles disponibles :\", len(DF_rvf)-DF_rvf['review_text'].isna().sum())\n","\n","  # On sélectionne la colonne qui nous intéresse en retirant les valeurs manquantes, et on fait un mélange aléatoire: \n","  S_reviews = DF_rvf['review_text'][~DF_rvf['review_text'].isna()].sample(frac=1, random_state=5406).reset_index(drop=True)\n","  display(S_reviews.head(4))\n","  \n","  # On enregistre ces données pour ce projet:\n","  S_reviews.to_csv(reviews_filename, header=False, index=False)\n","\n","else:\n","  S_reviews = pd.read_csv(reviews_filename, header=None).iloc[:, 0]\n","  display(S_reviews.head(4))\n"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["0    Cette cuvée a gagné en élégance et en délicate...\n","1    Bonne trame acide. Légères notes animales à l’...\n","2    Réservé, à la fois pur et nerveux, il s'appuie...\n","3    Un assemblage de meunier et chardonnay, pas d’...\n","Name: 0, dtype: object"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"wRHhbr2tGMAA","executionInfo":{"status":"ok","timestamp":1615969771102,"user_tz":-60,"elapsed":981,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"7ad244ad-b7a2-4965-99ab-fc6005cbad8b"},"source":["# Préparation des données:\n","import re\n","\n","# On ajoute un nouveau mot (token) qui a vocation à servir de déclencheur pour générer un nouveau commentaire de dégustation.\n","# On supprime également les informations de date du commentaire, parfois présentes.\n","# Enfin on ajoute un token de fin de séquence pour inciter le modèle à produire des commentaires de taille raisonnable.\n","L_first_tokens = [\"<|review|>\"]\n","L_reviews = [L_first_tokens[0] + \" \" + re.sub(r\"\\([^\\(\\)]*\\.[0-9][0-9][0-9][0-9]\\)\", \"\", review.strip()) for review in list(S_reviews)]\n","L_reviews = [review + \" <|end|>\" for review in L_reviews]\n","\n","# Affichons le résultat de cette préparation sur quelques lignes:\n","for i in range(27,32):\n","  print(L_reviews[i])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["<|review|> On sent des vignes qui ont du fond dans un vin mûr et structuré, qui reste simple en finale. <|end|>\n","<|review|> Un véritable jus de caillou croquant et tonique, un vin plein de répartie, singulier dans l'éclat très ferme de son fruit tendu, d'une rare intensité désaltérante et juteuse. <|end|>\n","<|review|> Il s’exprime sur le fruit noir. Il mêle virilité et élégance, avec une forte empreinte du terroir. <|end|>\n","<|review|> Derrière une fine réduction, il livre une note d’épices et de garrigue. Il lui faut un peu d’air pour libérer son fruit. Il offre une très belle qualité du fruit, du relief avec une jolie assise tannique mais sans dureté. Long en bouche, il possède un beau potentiel de garde et d’évolution. <|end|>\n","<|review|> Les vendanges ont été plus tardives qu’à Haut-Brion, mais le vin conserve une réelle fraîcheur et un fruit sapide. Beaucoup de crémeux avec une fine sucrosité et un boisé doux (60 % de bois neuf). Bouche de grand équilibre avec une saveur saline en finale dans un assemblage à quasi parts égales de merlot et de cabernet-sauvignon. <|end|>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3AoFhEEkGMAB","executionInfo":{"status":"ok","timestamp":1615969776220,"user_tz":-60,"elapsed":823,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"99f097bc-9b48-4553-cca8-4d64311561b8"},"source":["# On vérifie le nombre de lignes:\r\n","print(len(L_reviews))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["30667\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UK8BQJHyGMAD","executionInfo":{"status":"ok","timestamp":1615974530446,"user_tz":-60,"elapsed":8869,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"d6f62e10-79f2-4bb5-9309-d3faef8ed29f"},"source":["# On va s'appuyer sur un modèle de générateur GPT-2 (merci OpenAI) pré-entraîné sur la langue française (merci Antoine Louis),\n","# et on utilise la bibliothèque transformers (merci à HuggingFace): \n","!pip install transformers\n","from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n","import tensorflow as tf\n","\n","# On charge le modèle pré-entraîné et son tokenizer associé:\n","model_name = \"antoiloui/belgpt2\"\n","model = TFGPT2LMHeadModel.from_pretrained(model_name)\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","nb_added_tokens = 0"],"execution_count":66,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"],"name":"stdout"},{"output_type":"stream","text":["All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n","\n","All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at antoiloui/belgpt2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CB98yCiFGMAD","executionInfo":{"status":"ok","timestamp":1615974534511,"user_tz":-60,"elapsed":734,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"85908562-6f26-4223-ec33-64887010c9ad"},"source":["# On ajoute des tokens de déclenchement et de padding au tokenizer, et on prépare le modèle à recevoir ces nouveaux tokens:\n","nb_added_tokens += tokenizer.add_special_tokens({'pad_token': \"<|pad|>\", 'eos_token':\"<|end|>\"})\n","if len(L_first_tokens)>0:\n","    nb_added_tokens += tokenizer.add_special_tokens({'additional_special_tokens': L_first_tokens})\n","print(nb_added_tokens, \"token(s) ajoutés\")\n","\n","_ = model.resize_token_embeddings(tokenizer.vocab_size + nb_added_tokens)"],"execution_count":67,"outputs":[{"output_type":"stream","text":["3 token(s) ajoutés\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ru_n6lEGMAD","executionInfo":{"status":"ok","timestamp":1615974537700,"user_tz":-60,"elapsed":796,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"d6e83723-6a8e-41a2-9cb4-68f8917f175e"},"source":["# On vérifie la bonne définition des tokens de padding et de fin de séquence :\n","print(tokenizer.pad_token, \":\", tokenizer.pad_token_id)\n","assert tokenizer.pad_token_id!=None\n","print(tokenizer.eos_token, \":\", tokenizer.eos_token_id)\n","assert tokenizer.eos_token_id!=None"],"execution_count":68,"outputs":[{"output_type":"stream","text":["<|pad|> : 50257\n","<|end|> : 50258\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vTGjSK6Ea46x","executionInfo":{"status":"ok","timestamp":1615974540227,"user_tz":-60,"elapsed":890,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"45ba0a47-4d3a-446a-8d6a-483aa57b40d9"},"source":["# On vérifie qu'un commentaire de vin est inchangé après tokenisation puis détokenisation:\r\n","i = 4449\r\n","print(L_reviews[i])\r\n","\r\n","print(tokenizer.decode(tokenizer.encode(L_reviews[i])))\r\n","assert L_reviews[i] == tokenizer.decode(tokenizer.encode(L_reviews[i]))"],"execution_count":69,"outputs":[{"output_type":"stream","text":["<|review|> La précision de la matière entretient la force qui se dégage de ce vin. Amples, les tanins encore denses restent intégrés à la matière et soutiennent un fruité généreux. Les notes de cacao portent l'allonge avec puissance. <|end|>\n","<|review|> La précision de la matière entretient la force qui se dégage de ce vin. Amples, les tanins encore denses restent intégrés à la matière et soutiennent un fruité généreux. Les notes de cacao portent l'allonge avec puissance. <|end|>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"grHVIlkJGMAF","executionInfo":{"status":"ok","timestamp":1615974561271,"user_tz":-60,"elapsed":17655,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"6fe01c11-7b82-496d-b8ef-9b5c4fc016ae"},"source":["# On génère un commentaire aléatoire, avant entraînement spécifique (fine tuning) donc non exploitable à ce stade:\n","\n","# TO DO: optimiser si besoin (?) les paramètres de génération aléatoire \n","# cf. https://blog.fastforwardlabs.com/2019/05/29/open-ended-text-generation.html\n","\n","def pipote(max_length=200, skip_special_tokens=True):\n","  input = tokenizer.encode(L_first_tokens[0], return_tensors='tf')\n","  output = model.generate(\n","      input_ids=input,\n","      max_length=max_length,\n","      do_sample=True,\n","      pad_token_id=tokenizer.pad_token_id \n","  )\n","  return tokenizer.decode(output[0], skip_special_tokens=skip_special_tokens)\n","\n","print(pipote())"],"execution_count":70,"outputs":[{"output_type":"stream","text":["' t de quoi? Il veut qu' on lui fasse honneur aussi bien dans sa maison que chez lui ; mais rien... Rien... Il veut être grand. L' occasion m' est donnée de mettre le point sur le sujet de cette très belle exposition. Les autres modèles d' exception seront vendus dès le 15 décembre 2009. La famille le trouve toujours un peu froid dans sa chambre, mais lorsqu' ils commencent à parler, le couple s' empresse de se rapprocher pour avoir la chance d' avoir leur fille dans leurs bras. En utilisant cette technique, nous nous sommes assurés que l' état de l' air est parfaitement \" propre \" et que dans certains cas il ne l' est pas assez pour être dangereux, comme par exemple fumer par temps chaud. Je ne parle pas ici de tous les éléments à savoir. C' est là toute l' importance de cet ouvrage, pour la compréhension de la Bible. De retour à La Réunion en novembre 2013, en tant que directeur général en\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":405},"id":"K7VF-wKikS3g","executionInfo":{"status":"ok","timestamp":1615974568175,"user_tz":-60,"elapsed":18168,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"67c49bac-907e-4e58-c2b1-ceba0e3ad57b"},"source":["# Pour limiter les calculs inutiles et le besoin de padding, on ne va garder que 90% des revues, celles ayant le plus faible nombre de tokens.\r\n","# Le seuil calculé ci-dessous est à 64 tokens.\r\n","import seaborn as sns\r\n","unpadded = tokenizer(L_reviews, padding=False)\r\n","L_nbtokens = [len(t) for t in unpadded.input_ids]\r\n","DF_nbtokens = pd.DataFrame(pd.Series(L_nbtokens, name='nbtokens'))\r\n","sns.displot(kind='hist', data=DF_nbtokens, x='nbtokens', bins=25, aspect=3)\r\n","threshold = DF_nbtokens.nbtokens.quantile(0.9)\r\n","print(threshold)\r\n","\r\n","L_short_reviews = [L_reviews[i] for i in range(0, len(L_reviews)) if L_nbtokens[i]<=threshold]\r\n","print(len(L_short_reviews))"],"execution_count":71,"outputs":[{"output_type":"stream","text":["64.0\n","27729\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1080x360 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vKi80k21GMAF","executionInfo":{"status":"ok","timestamp":1615974573140,"user_tz":-60,"elapsed":13200,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"e901cc5e-42d2-4f6c-cc66-b277bba29570"},"source":["# On prépare les données d'entraînement du générateur:\n","# Le générateur prédit le mot suivant pour chaque mot (ou plutôt token, en l'occurrence wordpiece) du texte fourni en entrée.\n","# Donc l'ensemble d'apprentissage est constitué de tuples (x=entrée, y=sortie) où y est un décalage de x d'un token vers la droite.\n","\n","batch_size = 16\n","train_size = int(0.80*len(L_short_reviews)/batch_size)*batch_size\n","print(\"Taille des batches :\", batch_size)\n","print(\"Nombre de lignes dans la base d'apprentissage :\", train_size)\n","\n","encodings = tokenizer(L_short_reviews, padding=True, return_tensors='tf')\n","input_ids = encodings.input_ids\n","attention_mask = encodings.attention_mask\n","x = {'input_ids': input_ids[:, :-1], 'attention_mask': attention_mask[:, :-1]}\n","y = input_ids[:, 1:]\n","assert x['input_ids'].shape == y.shape\n","assert x['attention_mask'].shape == y.shape\n","full_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n","train_dataset = full_dataset.take(train_size).batch(batch_size).repeat()\n","test_dataset = full_dataset.skip(train_size).batch(batch_size)"],"execution_count":72,"outputs":[{"output_type":"stream","text":["Taille des batches : 16\n","Nombre de lignes dans la base d'apprentissage : 22176\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q_jrufaFGMAJ","executionInfo":{"status":"ok","timestamp":1615974573144,"user_tz":-60,"elapsed":10372,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}}},"source":["# On \"encapsule\" le modèle initial dans un modèle qui ne renvoie que les \"logit\" des probabilités des mots,\n","# ce à quoi on peut appliquer la fonction de coût classique (entropie croisée)\n","\n","class Pipotron(tf.keras.Model):\n","  def __init__(self, model):\n","    super().__init__(name=\"Pipotron\")\n","    self.gpt2 = model\n","  def __call__(self, input, training=False):    \n","    y = self.gpt2(input, training=training)\n","    return y.logits\n","\n","pipotron = Pipotron(model)"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"35dvJh0rGMAK","executionInfo":{"status":"ok","timestamp":1615974573145,"user_tz":-60,"elapsed":6704,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"5e884a02-7359-45aa-c71f-a41ba58786b8"},"source":["# On contrôle les formats d'entrée et de sortie du modèle (à ce stade il est déboussolé par notre token de déclenchement):\n","for features, labels in train_dataset.take(1):\n","  i=4\n","  for k in features.keys():\n","    print(k, \":\", features[k].shape)\n","  print(tokenizer.decode(features['input_ids'][i], skip_special_tokens=False))\n","  print(\"labels :\", labels.shape)\n","  print(tokenizer.decode(labels[i], skip_special_tokens=False))\n","  z = pipotron(features)\n","  print(\"output :\", z.shape)\n","  print(tokenizer.decode(tf.math.argmax(z[i], axis=-1), skip_special_tokens=False))"],"execution_count":74,"outputs":[{"output_type":"stream","text":["input_ids : (16, 63)\n","attention_mask : (16, 63)\n","<|review|> Un viognier fidèle à son bouquet exubérant, agréable et fluide. <|end|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|>\n","labels : (16, 63)\n","Un viognier fidèle à son bouquet exubérant, agréable et fluide. <|end|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|>\n","output : (16, 63, 50260)\n","'iversdeurnier, à son terroir,érant,5, frais,Ung.ttttlégléglégléglégléglégléglégtlégtttttttttttboisboisboisboisboisbbbbbbb.......\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IyE21qUmZc_H","executionInfo":{"status":"ok","timestamp":1615974586390,"user_tz":-60,"elapsed":726,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}}},"source":["# Paramétrage de l'entraînement :\r\n","\r\n","# TO DO : appliquer un learning_rate dégressif évolutif ?\r\n","\r\n","optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\r\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n","pipotron.compile(optimizer=optimizer, loss=loss)"],"execution_count":75,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IMGyjNUEGMAM","outputId":"d7b59efc-bd62-4f51-b445-0c0dfc2a91ac"},"source":["# ENTRAINEMENT (fine tuning) DU MODELE :\n","\n","# Pour voir la progression, on affiche le score à chaque 'round' (pseudo-epoch, qui est en fait une subdivision de la 'vraie' epoch\n","# si on considère qu'une vraie epoch consiste à passer toute la base d'entraînement une fois):\n","nb_epochs = 5\n","nb_steps_per_round = 400\n","nb_rounds = (nb_epochs*len(L_short_reviews))//(batch_size*nb_steps_per_round)\n","print(\"Nombre d'étapes (rounds) d'entraînement prévues :\", nb_rounds)\n","H_history = pipotron.fit(train_dataset, validation_data=test_dataset, epochs=nb_rounds, steps_per_epoch=nb_steps_per_round)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Nombre d'étapes (rounds) d'entraînement prévues : 21\n","Epoch 1/21\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2219c29ec0>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2219c29ec0>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f22354dac20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7f22354dac20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","400/400 [==============================] - ETA: 0s - loss: 2.4071WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","400/400 [==============================] - 130s 210ms/step - loss: 2.4061 - val_loss: 1.7800\n","Epoch 2/21\n"," 92/400 [=====>........................] - ETA: 48s - loss: 1.7827"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P5fDlFatX5Im"},"source":["# Sauvegarde du modèle:\r\n","import time\r\n","\r\n","fullpath = \"models/pipotron_\" + str(int(time.time()/60))\r\n","model.save_pretrained(fullpath)\r\n","print(\"MODEL SAVED AT :\", fullpath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBDvdTW8GMAM","executionInfo":{"status":"ok","timestamp":1615969886513,"user_tz":-60,"elapsed":73574,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"97a0e17d-e379-4e1d-f51b-21c595273149"},"source":["# Rechargement du modèle, si besoin :\r\n","\r\n","fullpath = \"models/pipotron_26931474\"\r\n","model = TFGPT2LMHeadModel.from_pretrained(fullpath)\r\n","pipotron = Pipotron(model)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n","\n","All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at models/pipotron_26931474.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zficreSVxbBH","executionInfo":{"status":"ok","timestamp":1615970173240,"user_tz":-60,"elapsed":17533,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"e23daa7e-0393-4460-99a8-c6060da3fea3"},"source":["# On affiche un exemple de commentaire généré par le modèle entraîné:\r\n","print(pipote())\r\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Un fruit bien expressif, avec une petite touche d'alcool, sur des arômes fumés. La bouche est ample et large, avec des tanins présents mais bien équilibrés. Belle allonge. Corset a été créée en 1970 et a pris sa pleine dimension en 2001. Un vin racé.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6owyBwF9Mp6E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615973197195,"user_tz":-60,"elapsed":1629,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"1a82b2fe-0609-4358-a3ea-756b3773aa33"},"source":["# Code de test, A SUPPRIMER (pour bien interpréter la fonction de coût (loss))\r\n","\r\n","for x, ytrue in test_dataset.take(1):\r\n","  ypred_logit = pipotron(x)\r\n","  ypred = tf.keras.activations.softmax(ypred_logit)\r\n","  print(ypred.shape)\r\n","  print(type(x['input_ids']))\r\n","  print(x['input_ids'].shape)\r\n","  #print(tokenizer.decode(x['input_ids'][0]))\r\n","  #print(tokenizer.decode(ytrue[0]))\r\n","  #print(tokenizer.decode(tf.math.argmax(ypred[0], axis=-1)))\r\n","  #print(tf.math.reduce_max(ypred[0], axis=-1))\r\n","  L_proba = [ypred[0, wp, ytrue[0, wp]].numpy() for wp in range(0, x['input_ids'].shape[1])]\r\n","  L_log = [-np.log(p) for p in L_proba]\r\n","  print(L_proba)\r\n","  print(L_log)\r\n","  print(\"Calcul manuel de la cross entropy :\", np.mean(L_log))\r\n","  print(\"Calcul par la fonction avec logits=True et aggrégation automatique :\", loss(ytrue[[0]], ypred_logit[[0]]))\r\n","  print(\"Calcul par la fonction avec softmax manuel, logits=False et aggrégation automatique :\", tf.keras.losses.SparseCategoricalCrossentropy()(ytrue[:1], ypred[:1]))\r\n","  loss2 = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\r\n","  z = loss2(ytrue[:1], ypred[:1])\r\n","  print(\"Calcul par la fonction avec logits=False et aggrégation manuelle :\", z)\r\n","  print(tf.reduce_mean(z))\r\n"],"execution_count":46,"outputs":[{"output_type":"stream","text":["(16, 250, 50260)\n","<class 'tensorflow.python.framework.ops.EagerTensor'>\n","(16, 250)\n","[0.001094727, 0.62489265, 0.09311333, 0.8183387, 0.2364887, 0.015966944, 0.010694073, 0.6817045, 0.26131544, 0.007629169, 0.00010274026, 0.8877495, 0.9994221, 0.012027676, 0.7127236, 0.005193919, 0.20330457, 0.50257313, 0.03159934, 0.061603017, 0.048487667, 0.0009430915, 0.84833044, 0.0384862, 0.6284416, 0.0029421214, 0.17510642, 0.038885277, 0.0018042829, 0.0012440161, 0.0008610667, 0.17916352, 0.12814155, 0.0023394967, 0.4549562, 0.0012356754, 0.21942392, 0.7452575, 0.023454243, 0.6364435, 0.9867569, 0.99999976, 0.99999976, 0.99999976, 0.9999999, 0.99999976, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.9999999, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.9999999, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.9999999, 0.9999999, 0.99999976, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.99999976, 0.9999999, 0.9999999, 0.99999976, 0.99999976, 0.9999999, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.99999976, 0.9999999, 0.99999976, 0.99999976, 0.9999999, 0.99999976, 0.9999999, 0.99999976, 0.9999999, 0.99999976, 0.9999999, 0.9999999, 0.9999999, 0.9999999, 0.9999999]\n","[6.8172503, 0.4701754, 2.3739378, 0.20047899, 1.4418548, 4.1372347, 4.538066, 0.38315898, 1.3420271, 4.8757763, 9.183307, 0.11906568, 0.0005780937, 4.420545, 0.33866158, 5.260267, 1.5930501, 0.6880141, 3.4546192, 2.7870445, 3.0264459, 6.966347, 0.16448505, 3.2574556, 0.46451223, 5.8286242, 1.7423613, 3.2471397, 6.317592, 6.68941, 7.0573387, 1.7194564, 2.0546198, 6.0578194, 0.78755414, 6.6961374, 1.5167497, 0.2940255, 3.752704, 0.45185965, 0.013331551, 2.384186e-07, 2.384186e-07, 2.384186e-07, 1.192093e-07, 2.384186e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 1.192093e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 1.192093e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 1.192093e-07, 1.192093e-07, 2.384186e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 2.384186e-07, 1.192093e-07, 1.192093e-07, 2.384186e-07, 2.384186e-07, 1.192093e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 2.384186e-07, 1.192093e-07, 2.384186e-07, 2.384186e-07, 1.192093e-07, 2.384186e-07, 1.192093e-07, 2.384186e-07, 1.192093e-07, 2.384186e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07, 1.192093e-07]\n","Calcul manuel de la cross entropy : 0.4901244\n","Calcul par la fonction avec logits=True et aggrégation automatique : tf.Tensor(0.49012446, shape=(), dtype=float32)\n","Calcul par la fonction avec softmax manuel, logits=False et aggrégation automatique : tf.Tensor(0.4950329, shape=(), dtype=float32)\n","Calcul par la fonction avec logits=False et aggrégation manuelle : tf.Tensor(\n","[[6.82204914e+00 4.73070741e-01 2.37777162e+00 2.05102399e-01\n","  1.44663322e+00 4.14183903e+00 4.54123449e+00 3.87865096e-01\n","  1.34517121e+00 4.87967777e+00 9.18734837e+00 1.23529546e-01\n","  5.57024684e-03 4.42365360e+00 3.43122363e-01 5.26514578e+00\n","  1.59792423e+00 6.92917287e-01 3.45948577e+00 2.79135442e+00\n","  3.03117490e+00 6.97119904e+00 1.69240922e-01 3.26235032e+00\n","  4.69230354e-01 5.83323050e+00 1.74695039e+00 3.25163031e+00\n","  6.32182646e+00 6.69370270e+00 7.06189394e+00 1.72406197e+00\n","  2.05883265e+00 6.06187153e+00 7.92018235e-01 6.70059776e+00\n","  1.52067566e+00 2.98244089e-01 3.75709772e+00 4.56024021e-01\n","  1.81038361e-02 5.01327636e-03 5.01339464e-03 5.01327636e-03\n","  5.01327636e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01327636e-03\n","  5.01339464e-03 5.01339464e-03 5.01315761e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01327636e-03 5.01327636e-03 5.01327636e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01327636e-03\n","  5.01327636e-03 5.01339464e-03 5.01327636e-03 5.01339464e-03\n","  5.01339464e-03 5.01327636e-03 5.01339464e-03 5.01339464e-03\n","  5.01327636e-03 5.01339464e-03 5.01327636e-03 5.01327636e-03\n","  5.01339464e-03 5.01327636e-03 5.01339464e-03 5.01339464e-03\n","  5.01315761e-03 5.01327636e-03 5.01327636e-03 5.01327636e-03\n","  5.01327636e-03 5.01327636e-03 5.01339464e-03 5.01339464e-03\n","  5.01327636e-03 5.01315761e-03 5.01327636e-03 5.01339464e-03\n","  5.01327636e-03 5.01327636e-03 5.01327636e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01315761e-03 5.01327636e-03\n","  5.01315761e-03 5.01327636e-03 5.01339464e-03 5.01351338e-03\n","  5.01339464e-03 5.01339464e-03 5.01351338e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01351338e-03\n","  5.01339464e-03 5.01339464e-03 5.01351338e-03 5.01339464e-03\n","  5.01351338e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01351338e-03 5.01351338e-03 5.01327636e-03 5.01351338e-03\n","  5.01351338e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01351338e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01327636e-03 5.01315761e-03\n","  5.01339464e-03 5.01351338e-03 5.01351338e-03 5.01339464e-03\n","  5.01339464e-03 5.01327636e-03 5.01327636e-03 5.01339464e-03\n","  5.01315761e-03 5.01339464e-03 5.01315761e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01327636e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01327636e-03 5.01327636e-03 5.01339464e-03\n","  5.01315761e-03 5.01339464e-03 5.01327636e-03 5.01315761e-03\n","  5.01339464e-03 5.01327636e-03 5.01327636e-03 5.01327636e-03\n","  5.01339464e-03 5.01315761e-03 5.01351338e-03 5.01327636e-03\n","  5.01339464e-03 5.01339464e-03 5.01315761e-03 5.01339464e-03\n","  5.01339464e-03 5.01327636e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01327636e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01327636e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01327636e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01327636e-03 5.01339464e-03 5.01327636e-03\n","  5.01339464e-03 5.01327636e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01327636e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01339464e-03\n","  5.01339464e-03 5.01339464e-03 5.01339464e-03 5.01327636e-03\n","  5.01339464e-03 5.01339464e-03]], shape=(1, 250), dtype=float32)\n","tf.Tensor(0.49503288, shape=(), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MfURp6ppuNzX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615973684375,"user_tz":-60,"elapsed":6342,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}},"outputId":"fdfcec7b-6cf9-411d-ec0d-9b9de1413658"},"source":[""],"execution_count":49,"outputs":[{"output_type":"stream","text":["[37, 37, 51, 28, 17, 36, 21, 41, 38, 45]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KZQLQvKduPIY","executionInfo":{"status":"ok","timestamp":1615974157303,"user_tz":-60,"elapsed":703,"user":{"displayName":"François Guérillon","photoUrl":"","userId":"03664453875370395754"}}},"source":[""],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"eskJ6G3QuOm4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ZB1QxGzuO5e"},"source":[""],"execution_count":null,"outputs":[]}]}